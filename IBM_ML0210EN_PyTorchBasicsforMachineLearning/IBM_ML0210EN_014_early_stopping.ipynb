{"cells":[{"cell_type":"markdown","metadata":{"id":"4B1oPgewCphq"},"source":["<h1>Linear regression: Training and Validation Data</h1>"]},{"cell_type":"markdown","metadata":{"id":"anB_tpZhCphr"},"source":["<h2>Table of Contents</h2>\n","<p>In this lab, you will perform early stopping and save the model that minimizes the total loss on the validation data for every iteration. <br><i>( <b>Note:</b> Early Stopping is a general term. We will focus on the variant where we use the validation data. You can also use a pre-determined number iterations</i>. )</p>\n","\n","<ul>\n","    <li><a href=\"#Makeup_Data\">Make Some Data</a></li>\n","    <li><a href=\"#LR_Loader_Cost\">Create a Linear Regression Object, Data Loader and Criterion Function</a></li>\n","    <li><a href=\"#Stop\">Early Stopping and Saving the Mode Inference</a></li>\n","    <li><a href=\"#Result\">View Results</a></li>\n","</ul>\n","\n","<p>Estimated Time Needed: <strong>15 min</strong></p>\n","\n","<hr>"]},{"cell_type":"markdown","metadata":{"id":"fu0KgaOVCphr"},"source":["<h2>Preparation</h2>"]},{"cell_type":"markdown","metadata":{"id":"20bCs6pYCphs"},"source":["We'll need the following libraries, and set the random seed."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ABR9g-YCCphs"},"outputs":[],"source":["# Import the libraries and set random seed\n","\n","from torch import nn\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch import nn,optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","torch.manual_seed(1)"]},{"cell_type":"markdown","metadata":{"id":"0Q48I_QgCpht"},"source":["<!--Empty Space for separating topics-->"]},{"cell_type":"markdown","metadata":{"id":"Ky1d5Tu2Cphu"},"source":["<h2 id=\"#Makeup_Data\">Make Some Data</h2>"]},{"cell_type":"markdown","metadata":{"id":"nly8iIP0Cphu"},"source":["First let's create some artificial data, in a dataset class.  The class will include the option to produce training data or validation data. The training data includes outliers."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"86PME2-dCphv"},"outputs":[],"source":["# Create Data Class\n","\n","class Data(Dataset):\n","\n","    # Constructor\n","    def __init__(self, train = True):\n","        if train == True:\n","            self.x = torch.arange(-3, 3, 0.1).view(-1, 1)\n","            self.f = -3 * self.x + 1\n","            self.y = self.f + 0.1 * torch.randn(self.x.size())\n","            self.len = self.x.shape[0]\n","            if train == True:\n","                self.y[50:] = 20\n","        else:\n","            self.x = torch.arange(-3, 3, 0.1).view(-1, 1)\n","            self.y = -3 * self.x + 1\n","            self.len = self.x.shape[0]\n","\n","    # Getter\n","    def __getitem__(self, index):\n","        return self.x[index], self.y[index]\n","\n","    # Get Length\n","    def __len__(self):\n","        return self.len"]},{"cell_type":"markdown","metadata":{"id":"zYt5Si5yCphv"},"source":["We create two objects, one that contains training data and a second that contains validation data, we will assume the training data has the outliers."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v3dL129jCphw"},"outputs":[],"source":["#Create train_data object and val_data object\n","\n","train_data = Data()\n","val_data = Data(train = False)"]},{"cell_type":"markdown","metadata":{"id":"KwyDlW3WCphw"},"source":["We overlay the training points in red over the function that generated the data and the test data. Notice the outliers are at x=-3 and around x=2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wbafg_m0Cphw"},"outputs":[],"source":["# Plot the training data points\n","\n","plt.plot(train_data.x.numpy(), train_data.y.numpy(), 'xr')\n","\n","plt.plot(val_data.x.numpy(), val_data.y.numpy(), 'xy')\n","plt.plot(train_data.x.numpy(), train_data.f.numpy())\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.legend(loc = 'upper right')\n","plt.show()\n","label = 'training cost'"]},{"cell_type":"markdown","metadata":{"id":"MzDQC9FHCphx"},"source":["<!--Empty Space for separating topics-->"]},{"cell_type":"markdown","metadata":{"id":"t9LZj-BHCphx"},"source":["<h2 id=\"LR_Loader_Cost\">Create a Linear Regression Class, Object, Data Loader, Criterion Function</h2>"]},{"cell_type":"markdown","metadata":{"id":"oOdDriMACphx"},"source":["Create linear regression model class."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ENkVw2DCphy"},"outputs":[],"source":["# Create linear regression model class\n","\n","from torch import nn\n","\n","class linear_regression(nn.Module):\n","\n","    # Constructor\n","    def __init__(self, input_size, output_size):\n","        super(linear_regression, self).__init__()\n","        self.linear = nn.Linear(input_size, output_size)\n","\n","    # Predition\n","    def forward(self, x):\n","        yhat = self.linear(x)\n","        return yhat"]},{"cell_type":"markdown","metadata":{"id":"KNnlxpNkCphy"},"source":["Create the model object"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fg-yqZvbCphy"},"outputs":[],"source":["# Create the model object\n","\n","model = linear_regression(1, 1)"]},{"cell_type":"markdown","metadata":{"id":"7Q9rGMWMCphz"},"source":["We create the optimizer, the criterion function and a Data Loader object."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PbXSN1dQCphz"},"outputs":[],"source":["# Create optimizer, cost function and data loader object\n","\n","optimizer = optim.SGD(model.parameters(), lr = 0.1)\n","criterion = nn.MSELoss()\n","trainloader = DataLoader(dataset = train_data, batch_size = 1)"]},{"cell_type":"markdown","metadata":{"id":"_qcLgZ14Cphz"},"source":["<!--Empty Space for separating topics-->"]},{"cell_type":"markdown","metadata":{"id":"nF5qbudwCph0"},"source":["<h2 id=\"Stop\">Early Stopping and Saving the Mode</h2>"]},{"cell_type":"markdown","metadata":{"id":"L8UmFdXICph0"},"source":["Run several epochs of gradient descent and save the model that performs best on the validation data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ivH3gf3YCph1"},"outputs":[],"source":["# Train the model\n","\n","LOSS_TRAIN = []\n","LOSS_VAL = []\n","n=1;\n","min_loss = 1000\n","\n","def train_model_early_stopping(epochs, min_loss):\n","    for epoch in range(epochs):\n","        for x, y in trainloader:\n","            yhat = model(x)\n","            loss = criterion(yhat, y)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            loss_train = criterion(model(train_data.x), train_data.y).item()\n","            loss_val = criterion(model(val_data.x), val_data.y).item()\n","            LOSS_TRAIN.append(loss_train)\n","            LOSS_VAL.append(loss_val)\n","            if loss_val < min_loss:\n","                value = epoch\n","                min_loss = loss_val\n","                torch.save(model.state_dict(), 'best_model.pt')\n","\n","train_model_early_stopping(20, min_loss)"]},{"cell_type":"markdown","metadata":{"id":"TG5XSG-pCph1"},"source":["<!--Empty Space for separating topics-->"]},{"cell_type":"markdown","metadata":{"id":"V1gBXqUwCph2"},"source":["<h2 id=\"Result\">View Results</h2>"]},{"cell_type":"markdown","metadata":{"id":"s1K_m6ObCph2"},"source":["View the  loss for every iteration on the training set and validation set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PkgsUUDaCph3"},"outputs":[],"source":["# Plot the loss\n","\n","plt.plot(LOSS_TRAIN, label = 'training cost')\n","plt.plot(LOSS_VAL, label = 'validation cost')\n","plt.xlabel(\"Iterations \")\n","plt.ylabel(\"Cost\")\n","plt.legend(loc = 'upper right')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"EQ1bCI53Cph4"},"source":["We will create a new linear regression object; we will use the parameters saved in the early stopping. The model must be the same input dimension and output dimension as the original model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HQwOe0TWCph4"},"outputs":[],"source":["# Create a new linear regression model object\n","\n","model_best = linear_regression(1,1)"]},{"cell_type":"markdown","metadata":{"id":"-LHd7ErNCph5"},"source":["Load the model parameters <code>torch.load()</code>, then assign them to the object <code>model_best</code> using the method <code>load_state_dict</code>."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W6llcxtICph5"},"outputs":[],"source":["# Assign the best model to model_best\n","\n","model_best.load_state_dict(torch.load('best_model.pt'))"]},{"cell_type":"markdown","metadata":{"id":"Wh7Zdw6KCph6"},"source":["Let's compare the prediction  from the model obtained using early stopping and the model derived from  using the maximum number of iterations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZBNemorZCph6"},"outputs":[],"source":["plt.plot(model_best(val_data.x).data.numpy(), label = 'best model')\n","plt.plot(model(val_data.x).data.numpy(), label = 'maximum iterations')\n","plt.plot(val_data.y.numpy(), 'rx', label = 'true line')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"h1kJPG7RCph7"},"source":["We can see the model obtained via  early stopping fits the data points much better. For more variations of early stopping see:"]},{"cell_type":"markdown","metadata":{"id":"EDCUzqvtCph7"},"source":["Prechelt, Lutz.<i> \"Early stopping-but when?.\" Neural Networks: Tricks of the trade. Springer, Berlin, Heidelberg, 1998. 55-69</i>."]},{"cell_type":"markdown","metadata":{"id":"su5CKoZICph8"},"source":[" Inference"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}